{
  "$id": "https://hypersync.io/schemas/prompt/request_v1.json",
  "$schema": "http://json-schema.org/draft-07/schema#",
  "description": "Schema for prompt requests with verbose mode support",
  "properties": {
    "local_preprocess": {
      "default": true,
      "description": "Enable local preprocessing pipeline",
      "type": "boolean"
    },
    "max_tokens": {
      "description": "Maximum tokens to generate",
      "minimum": 1,
      "type": "integer"
    },
    "metadata": {
      "description": "Additional metadata",
      "type": "object"
    },
    "model": {
      "description": "Target model",
      "type": "string"
    },
    "prompt": {
      "description": "The prompt text",
      "type": "string"
    },
    "provider": {
      "description": "Target provider ID",
      "type": "string"
    },
    "request_id": {
      "description": "Request identifier",
      "type": "string"
    },
    "session_id": {
      "description": "Session identifier",
      "type": "string"
    },
    "temperature": {
      "description": "Sampling temperature",
      "maximum": 2,
      "minimum": 0,
      "type": "number"
    },
    "user_id": {
      "description": "User identifier",
      "type": "string"
    },
    "verbose": {
      "default": false,
      "description": "Enable verbose output with token breakdown",
      "type": "boolean"
    }
  },
  "required": [
    "prompt"
  ],
  "title": "Prompt Request",
  "type": "object"
}